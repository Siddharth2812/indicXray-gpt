{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f93d4d4-9ad5-4aba-9002-98fce37b5ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/torch/distributed/_functional_collectives.py:22: UserWarning: Unable to import torchdynamo util `is_torchdynamo_compiling`, so won't support torchdynamo correctly\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LlavaLlamaForCausalLM' from 'llava.model' (/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/llava/model/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllava\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IMAGE_TOKEN_INDEX\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllava\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconversation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m conv_templates\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllava\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_pretrained_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/llava/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlavaLlamaForCausalLM\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LlavaLlamaForCausalLM' from 'llava.model' (/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/llava/model/__init__.py)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX\n",
    "from llava.conversation import conv_templates\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import tokenizer_image_token, KeywordsStoppingCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3fbea4-169e-47c0-92ae-521df784bbaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MODEL_TYPE_TO_PEFT_MODEL_MAPPING' from 'peft.mapping' (/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/peft/mapping.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mllavarad\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m conv_mode = \u001b[33m\"\u001b[39m\u001b[33mv1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m tokenizer, model, image_processor, context_len = \u001b[43mload_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Medical/GPT-4o/llava/model/builder.py:122\u001b[39m, in \u001b[36mload_pretrained_model\u001b[39m\u001b[34m(model_path, model_base, model_name, load_8bit, load_4bit, device_map, device, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# Load language model\u001b[39;00m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    121\u001b[39m         \u001b[38;5;66;03m# PEFT model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[32m    123\u001b[39m         tokenizer = AutoTokenizer.from_pretrained(model_base, use_fast=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    124\u001b[39m         model = AutoModelForCausalLM.from_pretrained(model_base, torch_dtype=torch.float16, low_cpu_mem_usage=\u001b[38;5;28;01mTrue\u001b[39;00m, device_map=\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/peft/__init__.py:22\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# flake8: noqa\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     20\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m0.7.1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     AutoPeftModel,\n\u001b[32m     24\u001b[39m     AutoPeftModelForCausalLM,\n\u001b[32m     25\u001b[39m     AutoPeftModelForSequenceClassification,\n\u001b[32m     26\u001b[39m     AutoPeftModelForSeq2SeqLM,\n\u001b[32m     27\u001b[39m     AutoPeftModelForTokenClassification,\n\u001b[32m     28\u001b[39m     AutoPeftModelForQuestionAnswering,\n\u001b[32m     29\u001b[39m     AutoPeftModelForFeatureExtraction,\n\u001b[32m     30\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[32m     33\u001b[39m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     inject_adapter_in_model,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmixed_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftMixedModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/peft/auto.py:31\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     AutoModel,\n\u001b[32m     23\u001b[39m     AutoModelForCausalLM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     AutoModelForTokenClassification,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftConfig\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpeft_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     PeftModel,\n\u001b[32m     34\u001b[39m     PeftModelForCausalLM,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     PeftModelForTokenClassification,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_BaseAutoPeftModel\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'MODEL_TYPE_TO_PEFT_MODEL_MAPPING' from 'peft.mapping' (/Users/dog/.pyenv/versions/3.11.1/lib/python3.11/site-packages/peft/mapping.py)"
     ]
    }
   ],
   "source": [
    "disable_torch_init()\n",
    "\n",
    "model_path = \"microsoft/llava-rad\"\n",
    "model_base = \"lmsys/vicuna-7b-v1.5\"\n",
    "model_name = \"llavarad\"\n",
    "conv_mode = \"v1\"\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, model_base, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1261ce-7a86-443e-b6fc-7970c5c7d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_file):\n",
    "    if image_file.startswith('http') or image_file.startswith('https'):\n",
    "        response = requests.get(image_file)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26157c7d-0dd4-43de-9a01-ce9d5b96b7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c41483-8acf-48dd-bbb0-f87f2bbe601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lungs are clear.  Cardiomediastinal silhouette and hilar contours\n",
      " are unremarkable.  No pleural effusion or pneumothorax.\n"
     ]
    }
   ],
   "source": [
    "image_file = \"/Users/dog/Downloads/drive-download-20250427T052722Z-001/png/AB_training_13.png\" # CXR w pneumothorax from Open-I\n",
    "query = \"<image>\\nDescribe the findings of the chest x-ray.\\n\"\n",
    "conv = conv_templates[conv_mode].copy()\n",
    "conv.append_message(conv.roles[0], query)\n",
    "conv.append_message(conv.roles[1], None)\n",
    "prompt = conv.get_prompt()\n",
    "\n",
    "image = load_image(image_file)\n",
    "image_tensor = image_processor.preprocess(image, return_tensors='pt')['pixel_values'][0].half().unsqueeze(0).cuda()\n",
    "\n",
    "input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda()\n",
    "\n",
    "stopping_criteria = KeywordsStoppingCriteria([\"</s>\"], tokenizer, input_ids)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    output_ids = model.generate(\n",
    "        input_ids,\n",
    "        images=image_tensor,\n",
    "        do_sample=False,\n",
    "        temperature=9.0,\n",
    "        max_new_tokens=5024,\n",
    "        use_cache=True,\n",
    "        stopping_criteria=[stopping_criteria])\n",
    "\n",
    "outputs = tokenizer.batch_decode(output_ids[:, input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "outputs = outputs.strip()\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9648a18-e25d-48f3-9ad5-79d4eeff12e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
